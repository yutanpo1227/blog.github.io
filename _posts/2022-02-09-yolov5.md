---
layout: post
title:  "YOLOv5を使ってロボットを検出する"
date:   2023-03-10 11:16　+0900
category: 開発
icon: git
keywords: tag1, tag2
year: 2023
folder: yolov5
image: /yolov5/featured.jpg
preview: 0
---

![Top]({{site.baseurl}}/post-img/開発/yolov5/yolov5.gif)

今回はサッカーロボットを作る上で正面のロボットを検出できれば強いなと思い**YOLOv5**を使って転移学習を行い物体検出を行ってみたいと思います。<br>
結論から言うと、YOLOv5はとても強力なモデルでしたがモデルが大きく推論に時間がかかるためロボットへの搭載はできませんでしたが、PC上では実行できたため今後Jetson Orin Nanoなどが手に入ればもう一度検証してみたいと思います。

<details open markdown="block">
  <summary><b>目次</b></summary>
- TOC
{:toc}
</details>

# 参考にしたサイト
・<span style="color: #00FF66; ">[https://qiita.com/suginaga/items/468ea7d232b8a24501bf](https://qiita.com/suginaga/items/468ea7d232b8a24501bf)</span>
<br>
・<span style="color: #00FF66; ">[https://farml1.com/yolov5/](https://farml1.com/yolov5/)</span>
<br><br>

# YOLOv5とは
YOLOv5とは、**YOLO**(You Only Look Once)と呼ばれる物体検出モデルの一つで、中でも処理速度、精度のバランスが良いと言われているモデルです。<br>
<br>

# YOLOv5の準備
まずは、YOLOv5をGitHubからクローンします。<br>
<span style="color: #00FF66; ">[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)</span>
<br>

次に、以下のコードを実行し必要なライブラリをインストールします。<br>
```bash
$ pip install -r requirements.txt
```
<br>

# データセット用の画像の収集
学習を行うためのデータセットの準備を行います。<br>
今回はサッカーロボットを検出したいためロボットの画像を準備します。<br>
準備する方法として手作業で集めるのも良いですが、今回は以下のPythonコードでGoogle検索画像を自動で100枚収集し使います。<br>
```python
from icrawler.builtin import BingImageCrawler
crawler = BingImageCrawler(storage={"root_dir": "保存フォルダ名"})
crawler.crawl(keyword="画像の検索ワード", max_num=100)
```

> ここら辺は著作権などが絡んできそうですが、調べたところデータセットとして画像を使う場合は著作権に関わらず使えるとのことでした。<br>
(生成系のAIだとまずいらしい)<br>

<br>

# アノテーション作業
集めた画像からアノテーション作業を行い、教師データを作成します。<br>
アノテーション作業には、**labelImg**を使います。labelImgの使い方は<span style="color: #00FF66; ">[こちら](https://laid-back-scientist.com/labelimg)</span>の記事を参考にしました。<br>
> アノテーションとは、画像や動画などのデータに対して、そのデータに含まれる物体の位置や種類などを記述することです。<br>

<br>


# データセットの配置
ここまで作成したデータセットを以下のようにyolov5フォルダに配置します。<br>
```
img    ┬ img.yaml
　　　 ｜　
　　　 ├ test  ┬ ***.jpg（画像）
　　　 ｜　　　├ ***.txt（ラベリングデータ）
　　　 ｜　　　├ ***.txt（画像）
　　　 ｜　　　├ ***.txt（ラベリングデータ）
　　　 ｜　    ・・・
　　　 ｜　　　　　
　　　 ├ train  ┬ ***.jpg（画像）
　　　 ｜　　 　├ ***.txt（ラベリングデータ）
　　　 ｜　　　 ├ ***.txt（画像）
　　　 ｜　　　 ├ ***.txt（ラベリングデータ）
　　　 ｜　　   ・・・
　　　 ｜　　　　　
　　　 └ val   ┬ ***.jpg（画像）
　　　  　　　 ├ ***.txt（ラベリングデータ）
　　　  　 　　├ ***.txt（画像）
　　　  　　　 ├ ***.txt（ラベリングデータ）
　　　  　　　  ・・・
```

img.yamlは以下のように記述します。<br>
```yaml
# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train: trainフォルダのパス
val: valフォルダのパス
test: テストフォルダのパス

# number of classes
nc: 2

# class names
names: ['Robot','Goal']
```
<br>

# 学習
学習を行います。<br>
学習にはyolov5ディレクトリ内で以下のコマンドを実行します。<br>
```bash
$ python train.py --data img/img.yaml --weights yolov5s.pt --epochs 200
```
後は完了するのを待つだけです。
<br>

# 推論の実行
最後に作成したモデルを使って推論を行います。<br>
推論には以下のコマンドを実行します。<br>
```bash
$ python detect.py --source 0 --weights yolov5s.pt
```
> リアルタイムでカメラを用いて推論する場合は--sourceに0を指定し、画像に対して行う場合は画像のパスを指定します。<br>

結果は以下のようになりました。<br>
gifなので分かりづらいですが、ちゃんとロボットを認識できています。(使用したロボットは未学習のもの)<br>
![result]({{site.baseurl}}/post-img/開発/yolov5/yolov5.gif)